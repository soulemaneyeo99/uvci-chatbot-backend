import google.generativeai as genai
from app.config import settings
from typing import List, Dict, Optional
import logging

# Configuration du logger
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Configuration de Gemini
try:
    genai.configure(api_key=settings.GOOGLE_API_KEY)
    logger.info("âœ… Gemini API configurÃ©e avec succÃ¨s")
except Exception as e:
    logger.error(f"âŒ Ã‰chec de configuration Gemini API: {e}")
    raise

class GeminiService:
    def __init__(self):
        """Initialise le service Gemini avec les modÃ¨les 2.5"""
        try:
            # Liste des modÃ¨les Gemini 2.5 Ã  essayer dans l'ordre
            model_candidates = [
                'gemini-2.5-flash',           # Le plus rapide
                'gemini-2.5-flash-lite',      # Version allÃ©gÃ©e
                'gemini-2.5-pro',             # Le plus puissant
            ]
            
            # Trouver le premier modÃ¨le qui fonctionne
            model_name = None
            for candidate in model_candidates:
                try:
                    test_model = genai.GenerativeModel(candidate)
                    # Test rapide
                    test_response = test_model.generate_content(
                        "Test", 
                        generation_config={'max_output_tokens': 5}
                    )
                    model_name = candidate
                    logger.info(f"âœ… ModÃ¨le sÃ©lectionnÃ©: {model_name}")
                    break
                except Exception as e:
                    logger.debug(f"âŒ ModÃ¨le {candidate} non disponible: {str(e)[:50]}")
                    continue
            
            if not model_name:
                # Utiliser le premier modÃ¨le disponible de la liste
                model_name = 'gemini-2.5-flash'
                logger.warning(f"âš ï¸  Utilisation du modÃ¨le par dÃ©faut: {model_name}")
            
            self.model = genai.GenerativeModel(model_name)
            self.model_name = model_name
            logger.info(f"ðŸš€ ModÃ¨le Gemini initialisÃ©: {model_name}")
            
        except Exception as e:
            logger.error(f"âŒ Erreur initialisation modÃ¨le: {e}")
            raise
    
    def _build_system_prompt(self) -> str:
        """Construit le prompt systÃ¨me pour le chatbot UVCI"""
        return """Tu es l'assistant virtuel officiel de l'UniversitÃ© Virtuelle de CÃ´te d'Ivoire (UVCI).

ðŸŽ“ TON RÃ”LE:
- Aider les Ã©tudiants avec des informations prÃ©cises sur l'UVCI
- RÃ©pondre aux questions sur les admissions, programmes, frais, calendrier acadÃ©mique
- ÃŠtre chaleureux, professionnel et encourageant
- Utiliser les documents fournis comme source principale

ðŸ“‹ RÃˆGLES:
1. Base-toi UNIQUEMENT sur les documents UVCI fournis
2. Si l'info n'est pas dans les documents, dis-le clairement
3. Sois concis (2-4 phrases sauf si dÃ©tails demandÃ©s)
4. Utilise des emojis appropriÃ©s 
5. Propose des questions de suivi pertinentes
6. Pour les questions complexes, suggÃ¨re de contacter l'administration

ðŸš« Ã€ Ã‰VITER:
- Inventer des informations
- Donner des conseils financiers/lÃ©gaux
- Partager des opinions personnelles
- Discuter de sujets hors UVCI"""

    def generate_response(
        self, 
        user_message: str, 
        context: Optional[List[Dict]] = None,
        rag_context: Optional[str] = None
    ) -> str:
        """GÃ©nÃ¨re une rÃ©ponse avec Gemini"""
        try:
            # Construire le prompt systÃ¨me
            system_prompt = self._build_system_prompt()
            
            # Ajouter le contexte RAG si disponible
            rag_section = ""
            if rag_context:
                rag_section = f"""

ðŸ“š DOCUMENTS UVCI PERTINENTS:
---
{rag_context}
---

Utilise ces documents pour rÃ©pondre Ã  la question de l'Ã©tudiant.
"""
            
            # Construire l'historique de conversation
            history_messages = ""
            if context:
                for msg in context[-6:]:  # 6 derniers messages
                    role = "Ã‰tudiant" if msg["role"] == "user" else "Assistant"
                    history_messages += f"{role}: {msg['content']}\n"
            
            # Prompt complet
            full_prompt = f"""{system_prompt}

{rag_section}

{history_messages}

Ã‰tudiant: {user_message}

Assistant UVCI:"""
            
            # GÃ©nÃ©rer la rÃ©ponse
            response = self.model.generate_content(
                full_prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=0.7,
                    max_output_tokens=2048,
                )
            )
            
            return response.text.strip()
            
        except Exception as e:
            logger.error(f"âŒ Erreur Gemini: {str(e)}")
            return "DÃ©solÃ©, je rencontre un problÃ¨me technique. Veuillez rÃ©essayer."
    
    def generate_conversation_title(self, first_message: str) -> str:
        """GÃ©nÃ¨re un titre court pour la conversation"""
        try:
            prompt = f"""GÃ©nÃ¨re un titre court (3-6 mots maximum) pour cette conversation.
RÃ©ponds UNIQUEMENT avec le titre, sans guillemets.

Question: {first_message}

Titre:"""
            
            response = self.model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=0.3,
                    max_output_tokens=15,
                )
            )
            
            title = response.text.strip().strip('"').strip("'").rstrip('.')
            return title[:100]
            
        except Exception as e:
            logger.warning(f"âš ï¸  Erreur titre: {e}")
            return first_message[:50] + "..." if len(first_message) > 50 else first_message

# Instance globale
gemini_service = GeminiService()
